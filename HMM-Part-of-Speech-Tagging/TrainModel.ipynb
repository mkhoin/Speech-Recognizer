{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from math import log\n",
    "import numpy as np\n",
    "incrementer = 0.0000000000000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileContents(filename):\n",
    "    data = None\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileFromCommandLine():\n",
    "    filename = sys.argv[1]\n",
    "    return getFileContents(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitWordTag(word_tag_pair):\n",
    "    splitted = word_tag_pair.split('/')\n",
    "    tag = splitted[-1]\n",
    "    word = '/'.join(splitted[:-1])\n",
    "    return word, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUniqueTags(tagged_data):\n",
    "    tags = {}\n",
    "    for line in tagged_data:\n",
    "        word_tag_pairs = line.strip().split(' ')\n",
    "        for word_tag_pair in word_tag_pairs:\n",
    "            word, tag = splitWordTag(word_tag_pair)\n",
    "            if tag in tags.keys():\n",
    "                tags[tag] += 1\n",
    "            else:\n",
    "                tags[tag] = 1\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpenProbabilities(tagged_data, all_tags_dict):\n",
    "    global incrementer\n",
    "    sentences_count = len(tagged_data)\n",
    "    open_tag_count_dict = {}\n",
    "    for line in tagged_data:\n",
    "        first_word_tag_pairs = line.strip().split(' ')[0]\n",
    "        word, tag = splitWordTag(first_word_tag_pairs)\n",
    "        if tag in open_tag_count_dict.keys():\n",
    "            open_tag_count_dict[tag] += 1\n",
    "        else:\n",
    "            open_tag_count_dict[tag] = 1\n",
    "    \n",
    "    #increment all existing tags count to one\n",
    "    open_tag_count_dict.update((tag, occurances + incrementer) for tag, occurances in open_tag_count_dict.items())\n",
    "    sentences_count += (sentences_count*incrementer)\n",
    "    \n",
    "    #add one two non-opening tags\n",
    "    for tag in all_tags_dict.keys():\n",
    "        try:\n",
    "            val = open_tag_count_dict[tag]\n",
    "        except KeyError as e:\n",
    "            open_tag_count_dict[tag] = incrementer\n",
    "            sentences_count += incrementer\n",
    "    \n",
    "    open_tag_count_dict.update((tag, log((occurances*1.0)/sentences_count)) for tag, occurances in open_tag_count_dict.items())\n",
    "    return open_tag_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCloseProbabilities(tagged_data, all_tags_dict):\n",
    "    global incrementer\n",
    "    sentences_count = len(tagged_data)\n",
    "    close_tag_count_dict = {}\n",
    "    for line in tagged_data:\n",
    "        last_word_tag_pairs = line.strip().split(' ')[-1]\n",
    "        word, tag = splitWordTag(last_word_tag_pairs)\n",
    "        if tag in close_tag_count_dict.keys():\n",
    "            close_tag_count_dict[tag] += 1\n",
    "        else:\n",
    "            close_tag_count_dict[tag] = 1\n",
    "            \n",
    "    #increment all existing tags count by one\n",
    "    close_tag_count_dict.update((tag, occurances + incrementer) for tag, occurances in close_tag_count_dict.items())\n",
    "    \n",
    "    sentences_count += (sentences_count*incrementer)\n",
    "    \n",
    "    #add one two non-closing tags\n",
    "    for tag in all_tags_dict.keys():\n",
    "        try:\n",
    "            val = close_tag_count_dict[tag]\n",
    "        except KeyError as e:\n",
    "            close_tag_count_dict[tag] = incrementer\n",
    "            sentences_count += incrementer\n",
    "            \n",
    "    close_tag_count_dict.update((tag, log((occurances*1.0)/sentences_count)) for tag, occurances in close_tag_count_dict.items())\n",
    "    return close_tag_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTransitionMatrix(tagged_data, tags_dict):\n",
    "    global incrementer\n",
    "    tags = tags_dict.keys()\n",
    "    tags.sort()\n",
    "    \n",
    "    tags_index_dict = {}\n",
    "    tags_index_dict_reverse = {}\n",
    "    for index, tag in enumerate(tags):\n",
    "        tags_index_dict[tag] = index\n",
    "        tags_index_dict_reverse[index] = tag\n",
    "    \n",
    "    tag_count = len(tags)\n",
    "    \n",
    "    #Change this line to np.ones for add 1 smoothing\n",
    "    transition_matrix = np.zeros(shape=(tag_count, tag_count))\n",
    "    \n",
    "    for line in tagged_data:\n",
    "        prev_tag = None\n",
    "        word_tag_pairs = line.strip().split(' ')\n",
    "        \n",
    "        for word_tag_pair in word_tag_pairs:\n",
    "            word, tag = splitWordTag(word_tag_pair)\n",
    "            \n",
    "            if prev_tag is not None:\n",
    "                transition_matrix[tags_index_dict[prev_tag]][tags_index_dict[tag]] += 1\n",
    "            \n",
    "            prev_tag = tag\n",
    "    \n",
    "    transition_matrix = transition_matrix + incrementer\n",
    "    \n",
    "    probability_transition_matrix = transition_matrix/transition_matrix.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    print \"Transition Values are NaN : \", np.argwhere(np.isnan(probability_transition_matrix))\n",
    "    probability_transition_matrix[np.isnan(probability_transition_matrix)] = incrementer\n",
    "    probability_transition_matrix = np.log(probability_transition_matrix)\n",
    "    return probability_transition_matrix.tolist(), tags_index_dict, tags_index_dict_reverse\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUniqueWords(tagged_data):\n",
    "    words = []\n",
    "    for line in tagged_data:\n",
    "        word_tag_pairs = line.strip().split(' ')\n",
    "        \n",
    "        for word_tag_pair in word_tag_pairs:\n",
    "            word, tag = splitWordTag(word_tag_pair)\n",
    "            words.append(word)\n",
    "    return list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEmissionProbabilities(tagged_data, tags_dict):\n",
    "    global incrementer\n",
    "    tags = tags_dict.keys()\n",
    "    tags.sort()\n",
    "    \n",
    "    words = getUniqueWords(tagged_data)\n",
    "    words.sort()\n",
    "    \n",
    "    tags_index_dict = {}\n",
    "    for index, tag in enumerate(tags):\n",
    "        tags_index_dict[tag] = index\n",
    "        \n",
    "    words_index_dict = {}\n",
    "    words_index_dict_reverse = {}\n",
    "    for index, word in enumerate(words):\n",
    "        words_index_dict[word] = index\n",
    "        words_index_dict_reverse[index] = word\n",
    "    \n",
    "    tag_count = len(tags)\n",
    "    word_count = len(words)\n",
    "    \n",
    "    # word_count + 1 => Last column for unseen words\n",
    "    emission_matrix = np.zeros(shape=(tag_count, word_count + 1))\n",
    "    \n",
    "    for line in tagged_data:\n",
    "        prev_tag = None\n",
    "        word_tag_pairs = line.strip().split(' ')\n",
    "        \n",
    "        for word_tag_pair in word_tag_pairs:\n",
    "            word, tag = splitWordTag(word_tag_pair)\n",
    "            \n",
    "            emission_matrix[tags_index_dict[tag]][words_index_dict[word]] += 1\n",
    "            \n",
    "            prev_tag = tag\n",
    "    #increment 1 in all the elements so that the last col for unseen words have non zero values\n",
    "    emission_matrix = emission_matrix + incrementer\n",
    "    probability_emission_matrix = emission_matrix/emission_matrix.sum(axis=1, keepdims=True)\n",
    "    print \"Emission Values are NaN : \", np.argwhere(np.isnan(probability_emission_matrix))\n",
    "    probability_emission_matrix[np.isnan(probability_emission_matrix)] = incrementer\n",
    "    probability_emission_matrix = np.log(probability_emission_matrix)\n",
    "    return probability_emission_matrix.tolist(), tags_index_dict, words_index_dict, words_index_dict_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printEmissionProbabilities(count):\n",
    "    counter = 0\n",
    "    global probability_emission_matrix, tags_index_dict, words_index_dict\n",
    "    word_count = len(words_index_dict.keys())\n",
    "    tag_count = len(tags_index_dict.keys())\n",
    "    for word, word_index in words_index_dict.iteritems():\n",
    "        for tag, tag_index in tags_index_dict.iteritems():\n",
    "            if probability_emission_matrix[tag_index][word_index] != 0:\n",
    "                print tag, \" => \", word, ' => ', probability_emission_matrix[tag_index][word_index]\n",
    "                counter += 1\n",
    "                if counter > count:\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeModelToFile(probability_transition_matrix, opening_probabilities, closing_probabilities, probability_emission_matrix, tags_index_dict, words_index_dict):\n",
    "    total_tags = len(tags_index_dict.keys())\n",
    "    total_words = len(words_index_dict.keys())\n",
    "        \n",
    "    lineCounter = 6\n",
    "    text = ''\n",
    "    \n",
    "    text += '---------------------TransitionMatrix---------------------' + '\\n'\n",
    "    lineCounter += 1\n",
    "    tr_start_line_number = lineCounter\n",
    "    tr_end_line_number = tr_start_line_number\n",
    "    for row in range(len(probability_transition_matrix)):\n",
    "        row_text = ''\n",
    "        for col in range(len(probability_transition_matrix[0])):\n",
    "            row_text += str(probability_transition_matrix[row][col]) + '\\t'\n",
    "        row_text = row_text.strip()\n",
    "        text += row_text + '\\n'\n",
    "        tr_end_line_number += 1\n",
    "    \n",
    "    text += '---------------------EmissionMatrix---------------------' + '\\n'\n",
    "    \n",
    "    em_start_line_number = tr_end_line_number + 1\n",
    "    em_end_line_number = em_start_line_number\n",
    "    for row in range(len(probability_emission_matrix)):\n",
    "        row_text = ''\n",
    "        for col in range(len(probability_emission_matrix[0])):\n",
    "            row_text += str(probability_emission_matrix[row][col]) + '\\t'\n",
    "        row_text = row_text.strip()\n",
    "        text += row_text + '\\n'\n",
    "        em_end_line_number += 1\n",
    "        \n",
    "    text += '---------------------OpeningClosingProbabilities---------------------' + '\\n'\n",
    "    \n",
    "    oc_start_line_number = em_end_line_number + 1\n",
    "    oc_end_line_number = oc_start_line_number\n",
    "    for tag in opening_probabilities:\n",
    "        tag_details = tag + '\\t' + str(opening_probabilities[tag]) + '\\t' + str(closing_probabilities[tag]) + '\\t' + str(tags_index_dict[tag]) + '\\n'\n",
    "        text += tag_details\n",
    "        oc_end_line_number += 1\n",
    "    \n",
    "    text += '---------------------Words---------------------' + '\\n'\n",
    "    \n",
    "    wi_start_line_number = oc_end_line_number + 1\n",
    "    wi_end_line_number = wi_start_line_number\n",
    "        \n",
    "    for word in words_index_dict:\n",
    "        word_details = word + '\\t' + str(words_index_dict[word]) + '\\n'\n",
    "        text += word_details\n",
    "        wi_end_line_number += 1\n",
    "    \n",
    "    \n",
    "    header = ''\n",
    "    header += 'total_tags:' + str(total_tags) + '\\n'\n",
    "    header += 'total_words:' + str(total_words) + '\\n'\n",
    "    header += 'tranistion_matrix:' + str(tr_start_line_number) + ':' + str(tr_end_line_number) + '\\n'\n",
    "    header += 'emission_matrix:' + str(em_start_line_number) + ':' + str(em_end_line_number) + '\\n'\n",
    "    header += 'open_close_probabilities:' + str(oc_start_line_number) + ':' + str(oc_end_line_number) + '\\n'\n",
    "    header += 'word_indexes:' + str(wi_start_line_number) + ':' + str(wi_end_line_number) + '\\n'\n",
    "    \n",
    "    text = header + text\n",
    "    filename = 'hmmmodel.txt'\n",
    "    with open(filename, 'w') as output_file:\n",
    "        output_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = getFileContents('data/en_train_tagged.txt')\n",
    "tags_dict = getUniqueTags(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_probabilities = getOpenProbabilities(tagged_data, tags_dict)\n",
    "closing_probabilities = getCloseProbabilities(tagged_data, tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_transition_matrix, tags_index_dict, tags_index_dict_reverse = buildTransitionMatrix(tagged_data, tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_emission_matrix, tags_index_dict, words_index_dict, words_index_dict_reverse = computeEmissionProbabilities(tagged_data, tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeModelToFile(probability_transition_matrix, opening_probabilities, closing_probabilities, probability_emission_matrix, tags_index_dict, words_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printEmissionProbabilities(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_count = len(tags_index_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readModelFile():\n",
    "    filename = 'hmmmodel.txt'\n",
    "    lines = []\n",
    "    with open(filename, 'r') as model_file:\n",
    "        lines = model_file.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseModel(lines):\n",
    "    total_tags = int(lines[0].strip().split(':')[-1])\n",
    "    total_words = int(lines[1].strip().split(':')[-1])\n",
    "    \n",
    "    tr_start_line_number = int(lines[2].strip().split(':')[-2])\n",
    "    tr_end_line_number = int(lines[2].strip().split(':')[-1])\n",
    "    \n",
    "    em_start_line_number = int(lines[3].strip().split(':')[-2])\n",
    "    em_end_line_number = int(lines[3].strip().split(':')[-1])\n",
    "    \n",
    "    oc_start_line_number = int(lines[4].strip().split(':')[-2])\n",
    "    oc_end_line_number = int(lines[4].strip().split(':')[-1])\n",
    "    \n",
    "    wi_start_line_number = int(lines[5].strip().split(':')[-2])\n",
    "    wi_end_line_number = int(lines[5].strip().split(':')[-1])\n",
    "    \n",
    "    print total_tags, total_words, tr_start_line_number, tr_end_line_number, em_start_line_number, em_end_line_number, oc_start_line_number,oc_end_line_number, wi_start_line_number, wi_end_line_number\n",
    "    \n",
    "    probability_transition_matrix = []\n",
    "    for line_number in range(tr_start_line_number, tr_end_line_number, 1):\n",
    "        row_values = (float, lines[line_number].strip().split('\\t'))\n",
    "        probability_transition_matrix.append(row_values)\n",
    "    \n",
    "    probability_emission_matrix = []\n",
    "    for line_number in range(em_start_line_number, em_end_line_number, 1):\n",
    "        row_values = (float, lines[line_number].strip().split('\\t'))\n",
    "        probability_emission_matrix.append(row_values)\n",
    "        \n",
    "    \n",
    "    opening_probabilities = {}\n",
    "    closing_probabilities = {}\n",
    "    \n",
    "    tags_index_dict = {}\n",
    "    tags_index_dict_reverse = {}\n",
    "    \n",
    "    for line_number in range(oc_start_line_number, oc_end_line_number, 1):\n",
    "        row_values = lines[line_number].strip().split('\\t')\n",
    "        tag_name = row_values[0]\n",
    "        open_p = float(row_values[1])\n",
    "        close_p = float(row_values[2])\n",
    "        index = int(row_values[3])\n",
    "        \n",
    "        opening_probabilities[tag_name] = open_p\n",
    "        closing_probabilities[tag_name] = close_p\n",
    "        tags_index_dict[tag_name] = index\n",
    "        tags_index_dict_reverse[index] = tag_name\n",
    "    \n",
    "    words_index_dict = {}\n",
    "    words_index_dict_reverse = {}\n",
    "    \n",
    "    for line_number in range(wi_start_line_number, wi_end_line_number, 1):\n",
    "        row_values = lines[line_number].strip().split('\\t')\n",
    "        word = row_values[0]\n",
    "        index = int(row_values[1])\n",
    "        words_index_dict[word] = index\n",
    "        words_index_dict_reverse[index] = word\n",
    "        \n",
    "    return opening_probabilities, closing_probabilities, probability_transition_matrix, probability_emission_matrix, tags_index_dict, tags_index_dict_reverse, words_index_dict, words_index_dict_reverse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostProbableTags(sentence):\n",
    "    global opening_probabilities, closing_probabilities, probability_transition_matrix, probability_emission_matrix, tags_index_dict, tags_index_dict_reverse, words_index_dict, words_index_dict_reverse \n",
    "    global tag_count, unseen_words\n",
    "    \n",
    "    sentence_words = sentence.strip().split(' ')\n",
    "    \n",
    "    sentence_len = len(sentence_words)\n",
    "    \n",
    "    viterbi_matrix = np.zeros(shape=(tag_count, sentence_len))\n",
    "    \n",
    "    tracing_matrix = [[None for x in range(sentence_len)] for y in range(tag_count)]\n",
    "    \n",
    "    for word_index in range(sentence_len):\n",
    "        word = sentence_words[word_index]\n",
    "        for model_tag in tags_index_dict:\n",
    "            model_tag_index = tags_index_dict[model_tag]\n",
    "            try:\n",
    "                word_emission_probability = probability_emission_matrix[model_tag_index][words_index_dict[word]]\n",
    "            except KeyError as e:\n",
    "                word_emission_probability = 1.0  #probability_emission_matrix[model_tag_index][-1]\n",
    "            \n",
    "            if word_index == 0:\n",
    "                try:\n",
    "                    tag_opening_probability = opening_probabilities[model_tag]\n",
    "                except KeyError as e:\n",
    "                    print \"tag_opening_probability : Keyerror encountered\"\n",
    "                    tag_opening_probability = 1.1754943508222875e-10\n",
    "                viterbi_matrix[model_tag_index][word_index] = tag_opening_probability + word_emission_probability\n",
    "            else:\n",
    "                max_probability = np.finfo(float).min\n",
    "                max_tag = None\n",
    "                for prev_model_tag in tags_index_dict:\n",
    "                    prev_model_tag_index = tags_index_dict[prev_model_tag]\n",
    "                    tag_transition_probability = probability_transition_matrix[prev_model_tag_index][model_tag_index]\n",
    "#                     if tag_transition_probability == 0.0:\n",
    "#                         print \"Transition probability still zero\"\n",
    "#                         tag_transition_probability = 1.1754943508222875e-10\n",
    "                    temp_probability = viterbi_matrix[prev_model_tag_index][word_index-1] + tag_transition_probability + word_emission_probability  \n",
    "                    if temp_probability > max_probability:\n",
    "                        max_probability = temp_probability\n",
    "                        max_tag = prev_model_tag\n",
    "                        \n",
    "                viterbi_matrix[model_tag_index][word_index] = max_probability\n",
    "                tracing_matrix[model_tag_index][word_index] = max_tag\n",
    "    \n",
    "    max_probability = np.finfo(float).min\n",
    "    max_probability_tag = None\n",
    "    for model_tag in tags_index_dict:\n",
    "        model_tag_index = tags_index_dict[model_tag]\n",
    "        temp_probability = 0.0\n",
    "        try:\n",
    "            tag_closing_probabilities = closing_probabilities[model_tag]\n",
    "        except KeyError as e:\n",
    "            print \"tag_closing_probabilities : Keyerror encountered\", \n",
    "            tag_closing_probabilities = 1.1754943508222875e-10\n",
    "        temp_probability =  tag_closing_probabilities + viterbi_matrix[model_tag_index][sentence_len-1]\n",
    "        if temp_probability > max_probability:\n",
    "            max_probability = temp_probability\n",
    "            max_probability_tag = model_tag\n",
    "\n",
    "    assigned_tags = [max_probability_tag]\n",
    "    current_best_tag = max_probability_tag\n",
    "    for col in range(sentence_len-1, 0, -1):\n",
    "        current_best_tag = tracing_matrix[tags_index_dict[current_best_tag]][col]\n",
    "        assigned_tags.append(current_best_tag)\n",
    "    assigned_tags = assigned_tags[::-1]\n",
    "    \n",
    "    anotated_sentence = ''\n",
    "    for index, assigned_tag in enumerate(assigned_tags):\n",
    "        anotated_sentence += str(sentence_words[index]) + '/' + str(assigned_tag) + ' '\n",
    "    \n",
    "    \n",
    "    return anotated_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total_tags:50\\n', 'total_words:19672\\n', 'tranistion_matrix:7:57\\n', 'emission_matrix:58:108\\n', 'open_close_probabilities:109:159\\n', 'word_indexes:160:19832\\n']\n"
     ]
    }
   ],
   "source": [
    "lines = readModelFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 19672 7 57 58 108 109 159 160 19832\n"
     ]
    }
   ],
   "source": [
    "opening_probabilities, closing_probabilities, probability_transition_matrix, probability_emission_matrix, tags_index_dict, tags_index_dict_reverse, words_index_dict, words_index_dict_reverse  = parseModel(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startPredicting():\n",
    "    test_data = getFileContents('data/en_dev_raw.txt')\n",
    "    output = ''\n",
    "    for test_line in test_data:\n",
    "        predicted_tagged_line = getMostProbableTags(test_line)\n",
    "        output += predicted_tagged_line + '\\n'\n",
    "    \n",
    "    output = output.strip()\n",
    "    \n",
    "    with open('hmmoutput.txt', 'w') as output_file:\n",
    "        output_file.write(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.9985785359\n"
     ]
    }
   ],
   "source": [
    "def getFileContents(filename):\n",
    "    data = None\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    return data\n",
    "\n",
    "def computeAccuracy():\n",
    "    dev_tagged_data = getFileContents('data/zh_dev_tagged.txt')\n",
    "    predicted_data = getFileContents('hmmoutput.txt')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for index, line in enumerate(dev_tagged_data):\n",
    "        predicted_tagged_line = predicted_data[index]\n",
    "        expected_tagged_line = dev_tagged_data[index]\n",
    "        \n",
    "        predicted_word_tag_pairs = predicted_tagged_line.strip().split(' ')\n",
    "        expected_word_tag_pairs = expected_tagged_line.strip().split(' ')\n",
    "        for index, predicted_word in enumerate(predicted_word_tag_pairs):\n",
    "            if predicted_word == expected_word_tag_pairs[index]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "#             if total % 100 == 0:\n",
    "#                 print correct, total, \" => \", (correct*100.0)/total\n",
    "    accuracy = (correct*100.0)/total\n",
    "    print accuracy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    computeAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "def f(x):\n",
    "    if x>0 and x<=1:\n",
    "        y= (0.5*(beta.pdf(0.5,8,5)))\n",
    "        return y\n",
    "    elif x>4 and x<=5:\n",
    "        y = 0.5*(x-4)\n",
    "        return y\n",
    "    elif x>5 and x<=6:\n",
    "        y=-0.5*(x-6)\n",
    "        return y\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.966797\n",
      "         Iterations: 3\n",
      "         Function evaluations: 7\n",
      "[ 0.00025]\n"
     ]
    }
   ],
   "source": [
    "# def f(x):\n",
    "#     return -1*x**2 + 8 * x\n",
    "max_x = scipy.optimize.fmin(lambda x: -f(x), 0, maxiter=10000, maxfun=10000)\n",
    "print max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
