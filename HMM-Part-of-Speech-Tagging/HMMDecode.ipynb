{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from math import log\n",
    "import numpy as np\n",
    "incrementer = 1.0\n",
    "\n",
    "\n",
    "def getFileContents(filename):\n",
    "    data = None\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    return data\n",
    "\n",
    "\n",
    "def getFileFromCommandLine():\n",
    "    filename = sys.argv[1]\n",
    "    return getFileContents(filename)\n",
    "\n",
    "\n",
    "\n",
    "def splitWordTag(word_tag_pair):\n",
    "    splitted = word_tag_pair.split('/')\n",
    "    tag = splitted[-1]\n",
    "    word = '/'.join(splitted[:-1])\n",
    "    return word, tag\n",
    "\n",
    "\n",
    "\n",
    "def getUniqueTags(tagged_data):\n",
    "    tags = {}\n",
    "    for line in tagged_data:\n",
    "        word_tag_pairs = line.strip().split(' ')\n",
    "        for word_tag_pair in word_tag_pairs:\n",
    "            word, tag = splitWordTag(word_tag_pair)\n",
    "            if tag in tags.keys():\n",
    "                tags[tag] += 1\n",
    "            else:\n",
    "                tags[tag] = 1\n",
    "    return tags\n",
    "\n",
    "\n",
    "def getUniqueWords(tagged_data):\n",
    "    words = []\n",
    "    for line in tagged_data:\n",
    "        word_tag_pairs = line.strip().split(' ')\n",
    "        \n",
    "        for word_tag_pair in word_tag_pairs:\n",
    "            word, tag = splitWordTag(word_tag_pair)\n",
    "            words.append(word)\n",
    "    return list(set(words))\n",
    "\n",
    "\n",
    "def readModelFile():\n",
    "    filename = 'hmmmodel.txt'\n",
    "    lines = []\n",
    "    with open(filename, 'r') as model_file:\n",
    "        lines = model_file.readlines()\n",
    "    return lines\n",
    "\n",
    "\n",
    "def parseModel(lines):\n",
    "    total_tags = int(lines[0].strip().split(':')[-1])\n",
    "    total_words = int(lines[1].strip().split(':')[-1])\n",
    "    \n",
    "    tr_start_line_number = int(lines[2].strip().split(':')[-2])\n",
    "    tr_end_line_number = int(lines[2].strip().split(':')[-1])\n",
    "    \n",
    "    em_start_line_number = int(lines[3].strip().split(':')[-2])\n",
    "    em_end_line_number = int(lines[3].strip().split(':')[-1])\n",
    "    \n",
    "    oc_start_line_number = int(lines[4].strip().split(':')[-2])\n",
    "    oc_end_line_number = int(lines[4].strip().split(':')[-1])\n",
    "    \n",
    "    wi_start_line_number = int(lines[5].strip().split(':')[-2])\n",
    "    wi_end_line_number = int(lines[5].strip().split(':')[-1])\n",
    "    \n",
    "    af_start_line_number = int(lines[6].strip().split(':')[-2])\n",
    "    af_end_line_number = int(lines[6].strip().split(':')[-1])\n",
    "    \n",
    "#     print total_tags, total_words, tr_start_line_number, tr_end_line_number, em_start_line_number, em_end_line_number, oc_start_line_number,oc_end_line_number, wi_start_line_number, wi_end_line_number\n",
    "    \n",
    "    probability_transition_matrix = []\n",
    "    for line_number in range(tr_start_line_number, tr_end_line_number, 1):\n",
    "        row_values = map(float, lines[line_number].strip().split('\\t'))\n",
    "        probability_transition_matrix.append(row_values)\n",
    "    \n",
    "    probability_emission_matrix = []\n",
    "    for line_number in range(em_start_line_number, em_end_line_number, 1):\n",
    "        row_values = map(float, lines[line_number].strip().split('\\t'))\n",
    "        probability_emission_matrix.append(row_values)\n",
    "        \n",
    "    \n",
    "    opening_probabilities = {}\n",
    "    closing_probabilities = {}\n",
    "    \n",
    "    tags_index_dict = {}\n",
    "    tags_index_dict_reverse = {}\n",
    "    \n",
    "    for line_number in range(oc_start_line_number, oc_end_line_number, 1):\n",
    "        row_values = lines[line_number].strip().split('\\t')\n",
    "        tag_name = row_values[0]\n",
    "        open_p = float(row_values[1])\n",
    "        close_p = float(row_values[2])\n",
    "        index = int(row_values[3])\n",
    "        \n",
    "        opening_probabilities[tag_name] = open_p\n",
    "        closing_probabilities[tag_name] = close_p\n",
    "        tags_index_dict[tag_name] = index\n",
    "        tags_index_dict_reverse[index] = tag_name\n",
    "    \n",
    "    words_index_dict = {}\n",
    "    words_index_dict_reverse = {}\n",
    "    \n",
    "    for line_number in range(wi_start_line_number, wi_end_line_number, 1):\n",
    "        row_values = lines[line_number].strip().split('\\t')\n",
    "        word = row_values[0]\n",
    "        index = int(row_values[1])\n",
    "        words_index_dict[word] = index\n",
    "        words_index_dict_reverse[index] = word\n",
    "        \n",
    "    additional_features = {}\n",
    "    for line_number in range(af_start_line_number, af_end_line_number, 1):\n",
    "        row_values = lines[line_number].strip().split('\\t')\n",
    "        feature_name = row_values[0]\n",
    "        feature_tag = row_values[1]\n",
    "        additional_features[feature_name] = feature_tag\n",
    "    \n",
    "        \n",
    "    return opening_probabilities, closing_probabilities, probability_transition_matrix, probability_emission_matrix, tags_index_dict, tags_index_dict_reverse, words_index_dict, words_index_dict_reverse, additional_features\n",
    "\n",
    "\n",
    "\n",
    "def getMostProbableTags(sentence):\n",
    "    global opening_probabilities, closing_probabilities, probability_transition_matrix, probability_emission_matrix, tags_index_dict, tags_index_dict_reverse, words_index_dict, words_index_dict_reverse \n",
    "    global tag_count, unseen_words, additional_features\n",
    "    \n",
    "    sentence_words = sentence.strip().split(' ')\n",
    "    \n",
    "    sentence_len = len(sentence_words)\n",
    "    \n",
    "    viterbi_matrix = np.zeros(shape=(tag_count, sentence_len))\n",
    "    \n",
    "    tracing_matrix = [[None for x in range(sentence_len)] for y in range(tag_count)]\n",
    "    \n",
    "    for col in range(sentence_len):\n",
    "        word = sentence_words[col]\n",
    "        for model_tag in tags_index_dict:\n",
    "            model_tag_index = tags_index_dict[model_tag]\n",
    "            try:\n",
    "                word_emission_probability = probability_emission_matrix[model_tag_index][words_index_dict[word]]\n",
    "                if word_emission_probability == 0.0:\n",
    "                    continue\n",
    "            except KeyError as e:\n",
    "                if word.count('=') > 10 or word.count('_') > 10 or word.count('*') > 10 or word.count('-') > 10 or word.count('+') > 10:\n",
    "                    if model_tag == additional_features['PAGE_SEP']:\n",
    "                        word_emission_probability = 1.0\n",
    "                    else:\n",
    "                        word_emission_probability = 1.1754943508222875e-30\n",
    "                elif any(word.lower().endswith(last) for last in ('.com', '.net', '.org', '.edu')) or word.startswith('http') or word.startswith('www.'):\n",
    "                    if model_tag == additional_features['URLS']:\n",
    "                        word_emission_probability = 1.0\n",
    "                    else:\n",
    "                        word_emission_probability = 1.1754943508222875e-30\n",
    "                elif [char.isdigit() for char in word].count(True) * 1.0 > len(word) * 0.4:\n",
    "                    if model_tag == additional_features['NUMERICS']:\n",
    "                        word_emission_probability = 1.0\n",
    "                    else:\n",
    "                        word_emission_probability = 1.1754943508222875e-30\n",
    "                else:\n",
    "                    try:\n",
    "                        word_emission_probability = probability_emission_matrix[model_tag_index][words_index_dict[word.lower()]]\n",
    "                    except KeyError as e:\n",
    "                        word_emission_probability = 1.0 #probability_emission_matrix[model_tag_index][-1]\n",
    "            \n",
    "            if col == 0:\n",
    "                try:\n",
    "                    tag_opening_probability = opening_probabilities[model_tag]\n",
    "                except KeyError as e:\n",
    "                    print \"tag_opening_probability : Keyerror encountered\"\n",
    "                    tag_opening_probability = 1.1754943508222875e-100\n",
    "                viterbi_matrix[model_tag_index][col] = tag_opening_probability * word_emission_probability\n",
    "            else:\n",
    "                max_probability = 0.0 #np.finfo(float).min\n",
    "                max_tag = None\n",
    "                \n",
    "                for prev_model_tag in tags_index_dict:\n",
    "                    prev_model_tag_index = tags_index_dict[prev_model_tag]\n",
    "                    tag_transition_probability = probability_transition_matrix[prev_model_tag_index][model_tag_index]\n",
    "                    if tag_transition_probability == 0.0:\n",
    "                        print \"Transition probability still zero\"\n",
    "                        tag_transition_probability = 1.1754943508222875e-100\n",
    "                    temp_probability = viterbi_matrix[prev_model_tag_index][col-1] * tag_transition_probability * word_emission_probability  \n",
    "                    if temp_probability >= max_probability:\n",
    "                        max_probability = temp_probability\n",
    "                        max_tag = prev_model_tag\n",
    "                        \n",
    "                viterbi_matrix[model_tag_index][col] = max_probability\n",
    "                tracing_matrix[model_tag_index][col] = max_tag\n",
    "    \n",
    "    max_probability = 0.0 #np.finfo(float).min\n",
    "    max_probability_tag = None\n",
    "    for model_tag in tags_index_dict:\n",
    "        model_tag_index = tags_index_dict[model_tag]\n",
    "        temp_probability = 0.0\n",
    "        try:\n",
    "            tag_closing_probabilities = closing_probabilities[model_tag]\n",
    "        except KeyError as e:\n",
    "            print \"tag_closing_probabilities : Keyerror encountered\", \n",
    "            tag_closing_probabilities = 1.1754943508222875e-100\n",
    "        temp_probability =  tag_closing_probabilities * viterbi_matrix[model_tag_index][sentence_len-1]\n",
    "        if temp_probability >= max_probability:\n",
    "            max_probability = temp_probability\n",
    "            max_probability_tag = model_tag\n",
    "\n",
    "    assigned_tags = [max_probability_tag]\n",
    "    current_best_tag = max_probability_tag\n",
    "    \n",
    "    for col in range(sentence_len-1, 0, -1):\n",
    "        current_best_tag = tracing_matrix[tags_index_dict[current_best_tag]][col]\n",
    "        assigned_tags.append(current_best_tag)\n",
    "    assigned_tags = assigned_tags[::-1]\n",
    "    \n",
    "    anotated_sentence = ''\n",
    "    for index, assigned_tag in enumerate(assigned_tags):\n",
    "        anotated_sentence += str(sentence_words[index]) + '/' + str(assigned_tag) + ' '\n",
    "    \n",
    "    \n",
    "    return anotated_sentence.strip()\n",
    "\n",
    "def startPredicting():\n",
    "    test_data = getFileFromCommandLine()\n",
    "#     test_data = getFileContents('data/zh_dev_raw.txt')\n",
    "    output = ''\n",
    "    for test_line in test_data:\n",
    "        predicted_tagged_line = getMostProbableTags(test_line)\n",
    "        output += predicted_tagged_line + '\\n'\n",
    "    \n",
    "    with open('hmmoutput.txt', 'w') as output_file:\n",
    "        output_file.write(output)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lines = readModelFile()\n",
    "    opening_probabilities, closing_probabilities, probability_transition_matrix, probability_emission_matrix, tags_index_dict, tags_index_dict_reverse, words_index_dict, words_index_dict_reverse, additional_features  = parseModel(lines)\n",
    "    print additional_features\n",
    "    tag_count = len(tags_index_dict.keys())\n",
    "    startPredicting()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getFileContents(filename):\n",
    "    data = None\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    return data\n",
    "\n",
    "def computeAccuracy():\n",
    "    dev_tagged_data = getFileContents('data/zh_dev_tagged.txt')\n",
    "    predicted_data = getFileContents('hmmoutput.txt')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for index, line in enumerate(dev_tagged_data):\n",
    "        predicted_tagged_line = predicted_data[index]\n",
    "        expected_tagged_line = dev_tagged_data[index]\n",
    "        \n",
    "        predicted_word_tag_pairs = predicted_tagged_line.strip().split(' ')\n",
    "        expected_word_tag_pairs = expected_tagged_line.strip().split(' ')\n",
    "        for index, predicted_word in enumerate(predicted_word_tag_pairs):\n",
    "            if predicted_word == expected_word_tag_pairs[index]:\n",
    "                correct += 1\n",
    "            else:\n",
    "                print predicted_word.ljust(30), ' => ',expected_word_tag_pairs[index]\n",
    "            total += 1\n",
    "#             if total % 100 == 0:\n",
    "#                 print correct, total, \" => \", (correct*100.0)/total\n",
    "    accuracy = (correct*100.0)/total\n",
    "    print accuracy\n",
    "\n",
    "computeAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese => 86.306562426\n",
    "# English => 89.0090663273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
